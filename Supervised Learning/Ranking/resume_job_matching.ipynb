{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e292f1-4c26-4377-8dd4-00e4b7e57eae",
   "metadata": {},
   "source": [
    "# Resume-Job Matching Model\n",
    "\n",
    "The pipeline is designed to match resumes to job postings by:\n",
    "- Preprocessing and cleaning text data.\n",
    "- Building embeddings and token-based features.\n",
    "- Combining semantic similarity (embeddings), lexical similarity (BM25), and overlap features.\n",
    "- Training a LightGBM to rank jobs for each resume.\n",
    "\n",
    "The model is trained using a 2022 listing of New York City Government job openings and web-scraped resumes; available at <u>https://www.kaggle.com/datasets/anandaramg/nyc-jobs-openings-2022</u> and <u>https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4a89c-cc61-4f11-b129-812d7ed649e5",
   "metadata": {},
   "source": [
    "## Stop-word Handling Overview\n",
    "\n",
    "In this pipeline, a custom stop-word list is used to filter out tokens that are\n",
    "unlikely to contribute meaningful information when matching resumes to jobs.\n",
    "\n",
    "- Generic function words: e.g., the, and, to, in, of\n",
    "  These are common across all texts and add little discriminative value.\n",
    "\n",
    "- Domain-specific filler words: e.g., management, department, coordinator, assistant \n",
    "  These appear frequently in job postings but do not help distinguish between roles.\n",
    "\n",
    "### How it works\n",
    "- During tokenization (`tokenize_informative`), any token that:\n",
    "  - is shorter than 3 characters,  \n",
    "  - is in the `STOPWORDS` set, or  \n",
    "  - is purely numeric  \n",
    "  is removed from the token list.\n",
    "\n",
    "- The resulting informative tokens are then used for:\n",
    "  - Building the informative vocabulary \n",
    "  - Computing BM25 lexical similarity\n",
    "  - Calculating resume–job token overlaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "808091dc-773b-4d3a-87ca-3606799e844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import lightgbm as lgb\n",
    "from rank_bm25 import BM25Okapi \n",
    "\n",
    "JOBS_CSV = \"NYC_Jobs.csv\"\n",
    "RESUMES_CSV = \"Resume.csv\"\n",
    "\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "USE_SUBSET = True\n",
    "MAX_RESUMES = 1000\n",
    "MAX_JOBS = 3000\n",
    "\n",
    "TOP_K = 5\n",
    "CAP_POSITIVES_PER_RESUME = 3\n",
    "NEGATIVES_PER_RESUME = 100\n",
    "\n",
    "RESULTS_DIR = \"./results\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "STOPWORDS = {\n",
    "    \"the\",\"and\",\"for\",\"with\",\"a\",\"to\",\"in\",\"of\",\"on\",\"at\",\"by\",\"from\",\"or\",\"as\",\"an\",\"be\",\"is\",\"are\",\"was\",\"were\",\n",
    "    \"management\",\"division\",\"department\",\"coordinator\",\"assistant\",\"director\",\"supervisor\",\"support\",\"services\",\n",
    "    \"city\",\"office\",\"program\",\"unit\",\"team\",\"senior\",\"junior\",\"lead\",\"staff\",\"administration\",\"administrative\", \"analyst\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80b2638-b159-451a-b8a2-1c63511dbb9a",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "**`load_jobs()`** \n",
    "- Input: Path to a CSV file containing job postings.\n",
    "- Output: DataFrame with non-null \"Business Title\" and \"Preferred Skills\".\n",
    "- Goal: Load and clean job postings for downstream processing.\n",
    "\n",
    "\n",
    "**`load_resumes()`** \n",
    "- Input: Path to a CSV file containing resumes.\n",
    "- Output: DataFrame with non-null \"Resume_str\". Adds \"Category\" column if missing.\n",
    "- Goal: Load resumes and ensure consistent schema.\n",
    "\n",
    "**`clean_text()`**\n",
    "- Input: Raw text string.\n",
    "- Output: Lowercased, alphanumeric-only, whitespace-normalized string.\n",
    "- Goal: Normalize text for tokenization and embedding.\n",
    "\n",
    "**`preprocess_jobs()`**\n",
    "- Input: Job postings DataFrame.\n",
    "- Output: Adds \"job_text\" column (cleaned concatenation of title + skills).\n",
    "- Goal: Create a unified text field for jobs.\n",
    "\n",
    "**`preprocess_resumes()`**\n",
    "- Input: Resume DataFrame.\n",
    "- Output: Adds \"resume_text\" column (cleaned resume text).\n",
    "- Goal: Create a unified text field for resumes.\n",
    "\n",
    "**`subset_frames()`**\n",
    "- Input: Job and resume DataFrames, max sample sizes.\n",
    "- Output: Subsampled DataFrames.\n",
    "- Goal: Enable faster debugging and model training by limiting dataset size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "290cbba3-115d-4192-8f21-193e8ed087af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jobs(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.dropna(subset=[\"Business Title\", \"Preferred Skills\"])\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def load_resumes(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.dropna(subset=[\"Resume_str\"])\n",
    "    if \"Category\" not in df.columns:\n",
    "        df[\"Category\"] = \"\"\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def preprocess_jobs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"job_text\"] = (df[\"Business Title\"].fillna(\"\") + \" \" +\n",
    "                      df[\"Preferred Skills\"].fillna(\"\")).map(clean_text)\n",
    "    return df\n",
    "\n",
    "def preprocess_resumes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"resume_text\"] = df[\"Resume_str\"].map(clean_text)\n",
    "    return df\n",
    "\n",
    "def subset_frames(jobs_df, resumes_df, max_jobs=MAX_JOBS, max_resumes=MAX_RESUMES):\n",
    "    if USE_SUBSET:\n",
    "        jobs_df = jobs_df.sample(n=min(max_jobs, len(jobs_df)), random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "        resumes_df = resumes_df.sample(n=min(max_resumes, len(resumes_df)), random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "        print(f\"Using subset: jobs={len(jobs_df)}, resumes={len(resumes_df)}\")\n",
    "    return jobs_df, resumes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895814f-fa18-44bf-9910-466e63c6af09",
   "metadata": {},
   "source": [
    "## Tokenization, Vocabulary, Embeddings\n",
    "**`tokenize_informative()`**\n",
    "- Input: Cleaned text string.\n",
    "- Output: List of tokens (length > 2, not in stopwords, not numeric).\n",
    "- Goal: Extract informative tokens for overlap and BM25.\n",
    "                                  \n",
    "**`build_informative_vocab()`**\n",
    "- Input: Job and resume DataFrames.\n",
    "- Output: Set of tokens that appear frequently enough but not too frequently.\n",
    "- Goal: Build a domain-specific vocabulary of informative words.\n",
    "\n",
    "\n",
    "**`class Embedder`**\n",
    "- Purpose: Wraps a SentenceTransformer model for encoding text into embeddings.\n",
    "- Methods:\n",
    "- `__init__()`: Loads transformer model.\n",
    "- `encode()`: Returns NumPy embeddings for a list of texts.\n",
    "- Goal: Provide semantic embeddings for resumes and jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fdcc1ac-af9b-4f73-b90d-eebd7be34b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_informative(text: str):\n",
    "    return [t for t in text.split() if len(t) > 2 and t not in STOPWORDS and not t.isdigit()]\n",
    "\n",
    "def build_informative_vocab(jobs_df, resumes_df, min_df=5, max_df_frac=0.1):\n",
    "    docs = jobs_df[\"job_text\"].tolist() + resumes_df[\"resume_text\"].tolist()\n",
    "    n_docs = len(docs)\n",
    "    df_counts = Counter()\n",
    "    for d in docs:\n",
    "        df_counts.update(set(tokenize_informative(d)))\n",
    "    max_df = int(max_df_frac * n_docs)\n",
    "    vocab = {tok for tok, df in df_counts.items() if df >= min_df and df <= max_df}\n",
    "    print(f\"Informative vocab size: {len(vocab)}\")\n",
    "    return vocab\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self, model_name=MODEL_NAME):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    def encode(self, texts):\n",
    "        return self.model.encode(texts, show_progress_bar=False, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee9597-56a5-4a7f-9a4a-a543b85e0010",
   "metadata": {},
   "source": [
    "## Feature Building (BM25 + Overlap + Embeddings)\n",
    "**`compute_resume_job_sims()`**\n",
    "- Input: Resume embeddings, job embeddings.\n",
    "- Output: List of cosine similarity arrays (one per resume).\n",
    "- Goal: Compute semantic similarity between resumes and jobs.\n",
    "    \n",
    "**`is_positive_pair()`**\n",
    "- Input: Resume text, job text, similarity scores, job index, vocab, thresholds.\n",
    "- Output: Boolean indicating if the resume–job pair is a positive match.\n",
    "- Goal: Weak labeling heuristic combining:\n",
    "- Embedding similarity (above percentile threshold).\n",
    "- Jaccard overlap of tokens.\n",
    "- Informative token overlap.\n",
    "\n",
    "**`build_features()`**\n",
    "- Input: Resume/job embeddings, DataFrames, vocab, BM25 model, token lists, thresholds.\n",
    "- Output:\n",
    "- X: Feature matrix (semantic + lexical + overlap + embedding diffs).\n",
    "- y: Labels (1 = positive, 0 = negative).\n",
    "- groups: Group sizes for LambdaRank (jobs per resume).\n",
    "- pair_index: Resume–job index pairs.\n",
    "- Goal: Construct training data for the ranker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30bfc0c1-58f1-4e52-8c15-e15a14d738d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_resume_job_sims(resume_embs, job_embs):\n",
    "    job_norms = np.linalg.norm(job_embs, axis=1) + 1e-9\n",
    "    sims_per_resume = []\n",
    "    for r_emb in resume_embs:\n",
    "        r_norm = np.linalg.norm(r_emb) + 1e-9\n",
    "        sims = np.dot(job_embs, r_emb) / (job_norms * r_norm)\n",
    "        sims_per_resume.append(sims)\n",
    "    return sims_per_resume\n",
    "\n",
    "def is_positive_pair(r_text, j_text, sims_for_resume, j_idx, vocab,\n",
    "                     emb_sim_percentile=0.9, jaccard_threshold=0.2):\n",
    "    r_tokens = set(tokenize_informative(r_text))\n",
    "    j_tokens = set(tokenize_informative(j_text))\n",
    "    informative_overlap = len((r_tokens & j_tokens) & vocab) > 0\n",
    "    sim = sims_for_resume[j_idx]\n",
    "    perc_threshold = np.quantile(sims_for_resume, emb_sim_percentile)\n",
    "    inter = len(r_tokens & j_tokens)\n",
    "    union = len(r_tokens | j_tokens)\n",
    "    jaccard = (inter / union) if union > 0 else 0.0\n",
    "    return (informative_overlap and sim >= perc_threshold) or (jaccard >= jaccard_threshold)\n",
    "\n",
    "def build_features(resume_embs, job_embs, resume_df, job_df, vocab,\n",
    "                   bm25, job_tokens_list,\n",
    "                   emb_sim_percentile=0.9, jaccard_threshold=0.2,\n",
    "                   cap_positives=CAP_POSITIVES_PER_RESUME,\n",
    "                   negatives_per_resume=NEGATIVES_PER_RESUME):\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    X, y, groups, pair_index = [], [], [], []\n",
    "    job_texts = job_df[\"job_text\"].tolist()\n",
    "    resume_texts = resume_df[\"resume_text\"].tolist()\n",
    "    sims_all = compute_resume_job_sims(resume_embs, job_embs)\n",
    "\n",
    "    for r_idx, r_emb in enumerate(resume_embs):\n",
    "        sims_for_resume = sims_all[r_idx]\n",
    "        positives, negatives = [], []\n",
    "        for j_idx, j_text in enumerate(job_texts):\n",
    "            if is_positive_pair(resume_texts[r_idx], j_text, sims_for_resume, j_idx, vocab,\n",
    "                                emb_sim_percentile, jaccard_threshold):\n",
    "                positives.append(j_idx)\n",
    "            else:\n",
    "                negatives.append(j_idx)\n",
    "        if cap_positives and len(positives) > cap_positives:\n",
    "            positives = list(rng.choice(positives, size=cap_positives, replace=False))\n",
    "        chosen_jobs = positives.copy()\n",
    "        if negatives:\n",
    "            sampled_negatives = rng.choice(negatives, size=min(negatives_per_resume, len(negatives)), replace=False)\n",
    "            chosen_jobs.extend(sampled_negatives)\n",
    "        r_tokens = tokenize_informative(resume_texts[r_idx])\n",
    "        scores_all = bm25.get_scores(r_tokens)   \n",
    "        for j_idx in chosen_jobs:\n",
    "            sim = sims_for_resume[j_idx]\n",
    "            dot = float(np.dot(r_emb, job_embs[j_idx]))\n",
    "            bm25_score = scores_all[j_idx]       \n",
    "            overlap_count = len(set(r_tokens) & set(job_tokens_list[j_idx]))\n",
    "            feat = np.concatenate([[sim, dot, bm25_score, overlap_count],\n",
    "                                   np.abs(r_emb - job_embs[j_idx])])\n",
    "            X.append(feat)\n",
    "            y.append(1 if j_idx in positives else 0)\n",
    "            pair_index.append((r_idx, j_idx))\n",
    "        groups.append(len(chosen_jobs))\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int16), groups, pair_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622fff9c-0e9d-477e-8656-de96eee00504",
   "metadata": {},
   "source": [
    "## Ranker (Learning-to-Rank with LightGBM)\n",
    "**`class Ranker`**\n",
    "- Purpose: Train and apply a LambdaRank model for resume–job ranking.\n",
    "- Attributes:\n",
    "- params: Default LightGBM LambdaRank parameters.\n",
    "- model: Trained LightGBM model.\n",
    "\n",
    "**`fit()`**\n",
    "- Input: Training features, labels, group sizes, optional validation set.\n",
    "- Output: Trains LightGBM LambdaRank model.\n",
    "- Goal: Learn ranking function from weakly labeled pairs.\n",
    "    \n",
    "**`predict()`**\n",
    "- Input: Feature matrix.\n",
    "- Output: Predicted ranking scores.\n",
    "- Goal: Rank jobs for resumes.\n",
    "                 \n",
    "**`build_pair_features_for_one_resume()`**\n",
    "- Input: Resume embedding, job embeddings, BM25 model, job tokens, resume text.\n",
    "- Output: Feature matrix for all job candidates for a single resume.\n",
    "- Goal: Generate features for inference (ranking jobs for one resume).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "298fa7d5-4a04-4856-aa09-567db320c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker:\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        self.params = params or {\n",
    "            \"objective\": \"lambdarank\",\n",
    "            \"metric\": \"ndcg\",\n",
    "            \"ndcg_eval_at\": [5, 10],\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"num_leaves\": 31,\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "\n",
    "    def fit(self, X, y, groups, num_boost_round=200, valid=None,\n",
    "            early_stopping_rounds=20, log_period=20):\n",
    "        train_data = lgb.Dataset(X, label=y, group=groups)\n",
    "        valid_sets = []\n",
    "        if valid is not None:\n",
    "            X_val, y_val, groups_val = valid\n",
    "            valid_sets.append(lgb.Dataset(X_val, label=y_val, group=groups_val))\n",
    "        callbacks = []\n",
    "        if valid_sets and early_stopping_rounds:\n",
    "            callbacks.append(lgb.early_stopping(early_stopping_rounds))\n",
    "        callbacks.append(lgb.log_evaluation(period=log_period))\n",
    "        self.model = lgb.train(self.params, train_data, num_boost_round=num_boost_round,\n",
    "                               valid_sets=valid_sets if valid_sets else None, callbacks=callbacks)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X, num_iteration=getattr(self.model, \"best_iteration\", None))\n",
    "\n",
    "    def build_pair_features_for_one_resume(self, resume_emb, job_embs, bm25, job_tokens_list, resume_text):\n",
    "        sims = np.dot(job_embs, resume_emb) / (\n",
    "            np.linalg.norm(job_embs, axis=1) * np.linalg.norm(resume_emb) + 1e-9\n",
    "        )\n",
    "        r_tokens = tokenize_informative(resume_text)\n",
    "        X = []\n",
    "        scores_all = bm25.get_scores(r_tokens)\n",
    "        for j_idx in range(len(job_embs)):\n",
    "            dot = float(np.dot(resume_emb, job_embs[j_idx]))\n",
    "            bm25_score = scores_all[j_idx]\n",
    "            overlap_count = len(set(r_tokens) & set(job_tokens_list[j_idx]))\n",
    "            feat = np.concatenate([[sims[j_idx], dot, bm25_score, overlap_count],\n",
    "                                   np.abs(resume_emb - job_embs[j_idx])])\n",
    "            X.append(feat)\n",
    "        return np.array(X, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5a411-b203-428e-ba32-b471b757f831",
   "metadata": {},
   "source": [
    "## Evaluation Helpers\n",
    "**`compute_ranking_metrics()`**\n",
    "\n",
    "Inputs:\n",
    "- ranked_jobs: List of job dictionaries, each with keys:\n",
    "- \"skills\": set of tokens for the job.\n",
    "- \"score\": predicted relevance score.\n",
    "- \"id\": job identifier.\n",
    "- resume_tokens: Set of tokens from the resume.\n",
    "- thres: Dictionary of thresholds for Jaccard similarity, e.g.: {\"high\": 0.5, \"medium\": 0.3, \"low\": 0.1}\n",
    "\n",
    "Outputs: \n",
    "- Dictionary of evaluation metrics:\n",
    "- precision5_weak: Precision at top-5 (weak labels via Jaccard).\n",
    "- ndcg10_weak: Normalized Discounted Cumulative Gain at top-10.\n",
    "- separation: Difference between mean scores of top vs. bottom jobs.\n",
    "- diversity_entropy: Entropy of skill distribution among top-10 jobs (higher = more diverse).\n",
    "- duplicate_penalty: Count of duplicate job IDs in top-10.\n",
    "\n",
    "Goal: Provide weak evaluation metrics for ranking quality, balancing relevance, diversity, and redundancy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74974797-8d8a-4c8c-82b8-d18546c05fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranking_metrics(ranked_jobs, resume_tokens, thres):\n",
    "    rels = []\n",
    "    for j in ranked_jobs:\n",
    "        inter = len(resume_tokens & j[\"skills\"])\n",
    "        union = len(resume_tokens | j[\"skills\"])\n",
    "        jaccard = (inter / union) if union > 0 else 0.0\n",
    "        if jaccard >= thres[\"high\"]:\n",
    "            rels.append(3)\n",
    "        elif jaccard >= thres[\"medium\"]:\n",
    "            rels.append(2)\n",
    "        elif jaccard >= thres[\"low\"]:\n",
    "            rels.append(1)\n",
    "        else:\n",
    "            rels.append(0)\n",
    "\n",
    "    k5, k10 = 5, min(10, len(ranked_jobs))\n",
    "    precision5 = sum(r > 0 for r in rels[:k5]) / max(1, k5)\n",
    "    discounts = [1/np.log2(i+2) for i in range(k10)]\n",
    "    dcg = sum(r * d for r, d in zip(rels[:k10], discounts))\n",
    "    ideal = sorted(rels, reverse=True)[:k10]\n",
    "    idcg = sum(r * d for r, d in zip(ideal, discounts)) or 1.0\n",
    "    ndcg = dcg / idcg\n",
    "\n",
    "    scores = [j[\"score\"] for j in ranked_jobs[:k10]]\n",
    "    sep = (np.mean(scores[:min(5, len(scores))]) - np.mean(scores[-min(5, len(scores)):])) if len(scores) >= 2 else 0.0\n",
    "\n",
    "    top_skills = [s for j in ranked_jobs[:k10] for s in j[\"skills\"]]\n",
    "    skill_counts = {}\n",
    "    for s in top_skills:\n",
    "        skill_counts[s] = skill_counts.get(s, 0) + 1\n",
    "    probs = np.array(list(skill_counts.values())) / max(1, len(top_skills))\n",
    "    diversity_entropy = float(-np.sum(probs * np.log(probs + 1e-9))) if len(probs) > 0 else 0.0\n",
    "\n",
    "    job_ids = [j[\"id\"] for j in ranked_jobs[:k10]]\n",
    "    duplicates = len(job_ids) - len(set(job_ids))\n",
    "\n",
    "    return {\n",
    "        \"precision5_weak\": float(precision5),\n",
    "        \"ndcg10_weak\": float(ndcg),\n",
    "        \"separation\": float(sep),\n",
    "        \"diversity_entropy\": float(diversity_entropy),\n",
    "        \"duplicate_penalty\": float(duplicates)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d604a81-196c-4dbe-b642-bd86c91523d6",
   "metadata": {},
   "source": [
    "## Orchestration: End-to-End Pipeline\n",
    "This section ties together all components into a full workflow, training a LightGBM LambdaRank model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "211cff1c-d76e-45c9-a9df-9d07bca045a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Using subset: jobs=3000, resumes=1000\n",
      "Embedding texts...\n",
      "Building informative vocab...\n",
      "Informative vocab size: 7578\n",
      "Building BM25 index...\n",
      "Features built\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preprocessing data...\")\n",
    "jobs_df = preprocess_jobs(load_jobs(JOBS_CSV))\n",
    "resumes_df = preprocess_resumes(load_resumes(RESUMES_CSV))\n",
    "jobs_df, resumes_df = subset_frames(jobs_df, resumes_df)\n",
    "\n",
    "print(\"Embedding texts...\")\n",
    "embedder = Embedder(MODEL_NAME)\n",
    "job_embeddings = embedder.encode(jobs_df[\"job_text\"].tolist())\n",
    "resume_embeddings = embedder.encode(resumes_df[\"resume_text\"].tolist())\n",
    "\n",
    "print(\"Building informative vocab...\")\n",
    "vocab = build_informative_vocab(jobs_df, resumes_df)\n",
    "\n",
    "print(\"Building BM25 index...\")\n",
    "job_tokens_list = [tokenize_informative(t) for t in jobs_df[\"job_text\"].tolist()]\n",
    "bm25 = BM25Okapi(job_tokens_list)\n",
    "\n",
    "X, y, groups, pair_index = build_features(\n",
    "    resume_embeddings, job_embeddings, resumes_df, jobs_df,\n",
    "    vocab=vocab, bm25=bm25, job_tokens_list=job_tokens_list,\n",
    "    emb_sim_percentile=0.8, jaccard_threshold=0.1\n",
    ")\n",
    "print(\"Features built\")\n",
    "\n",
    "final_params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [5, 10],\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_leaves\": 15,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "final_ranker = Ranker(final_params)\n",
    "final_ranker.fit(X, y, groups, num_boost_round=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab303967-672e-4695-bcd3-60bb29efddfd",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Testing the model on a new resumes outside of the training data to identify the top 5 job matches it predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dce85da-dd5e-44fa-892b-a013b0b3af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 5 unique job matches for Data Analyst resume ===\n",
      "  Analysis and Reporting Analyst (score: 5.285)\n",
      "  Data Analyst (score: 5.044)\n",
      "  COOP and Emergency Management Intern (score: 4.645)\n",
      "  GEOGRAPHIC INFORMATION SYSTEMS (GIS) SPECIALIST (score: 4.541)\n",
      "  ASSOCIATE DATA SCIENTIST (score: 4.310)\n",
      "\n",
      "=== Top 5 unique job matches for Healthcare Nurse resume ===\n",
      "  WTC Case Management Nurse (score: 4.837)\n",
      "  Supervising Public Health Nurse, Bureau of School Health/SH Nursing Services & Prof Dev (score: 3.292)\n",
      "  Public Health Nurse, I, Bureau of School Health (score: 2.815)\n",
      "  Supervising Health Nurse, Bureau of School Health/SH Nursing Services & Prof Dev (score: 1.594)\n",
      "  Staff Nurse (Part-Time) (score: 1.566)\n",
      "\n",
      "=== Top 5 unique job matches for Teacher resume ===\n",
      "  CIVIC ENGAGEMENT STUDIO SUMMER COLLEGE INTERN (score: 2.495)\n",
      "  Planner (score: -2.151)\n",
      "  Trout in the Classroom Program Coordinator (score: -2.315)\n",
      "  RESIDENT ENGAGEMENT ZONE COORDINATOR (score: -2.640)\n",
      "  BROOKLYN BOROUGH OFFICE SUMMER COLLEGE INTERN (score: -2.716)\n",
      "\n",
      "=== Top 5 unique job matches for Software Engineer resume ===\n",
      "  SOFTWARE ENGINEER (score: 2.675)\n",
      "  Senior Data Engineer (score: 1.987)\n",
      "  DevOps Engineer (score: 0.759)\n",
      "  CERTIFIED IT DEVELOPER (APPLICATIONS) (score: 0.621)\n",
      "  WEB APPLICATION DEVELOPER (score: -0.296)\n",
      "\n",
      "=== Top 5 unique job matches for Financial Analyst resume ===\n",
      "  Senior/Supervising Analyst  Environmental Sustainability and Resiliency (score: 3.923)\n",
      "  Investment Officer- Fixed Income (score: 3.409)\n",
      "  Risk Officer (Asset Management) (score: 3.016)\n",
      "  Energy Program Analyst (score: 2.665)\n",
      "  Staff Analyst (score: 2.649)\n",
      "\n",
      "=== Top 5 unique job matches for Graphic Designer resume ===\n",
      "  Graphic Design College Intern (score: 4.289)\n",
      "  Project Manager (score: 1.610)\n",
      "  Architectural Designer (score: 0.274)\n",
      "  Multimedia Designer/Systems Analyst (score: 0.149)\n",
      "  UX Designer (score: -0.666)\n"
     ]
    }
   ],
   "source": [
    "test_resumes = {\n",
    "    \"Data Analyst\": \"Experienced data analyst with SQL, Python, and Tableau skills\",\n",
    "    \"Healthcare Nurse\": \"Registered nurse with patient care, clinical experience, and hospital administration background\",\n",
    "    \"Teacher\": \"High school teacher skilled in curriculum design, classroom management, and student engagement\",\n",
    "    \"Software Engineer\": \"Full-stack developer with expertise in Java, React, cloud deployment, and API design\",\n",
    "    \"Financial Analyst\": \"Finance professional with Excel, risk modeling, and investment analysis experience\",\n",
    "    \"Graphic Designer\": \"Creative designer with Adobe Photoshop, Illustrator, and branding project experience\"\n",
    "}\n",
    "\n",
    "for label, resume_text in test_resumes.items():\n",
    "    print(f\"\\n=== Top 5 unique job matches for {label} resume ===\")\n",
    "    \n",
    "    cleaned = clean_text(resume_text)\n",
    "    resume_emb = embedder.encode([cleaned])[0]\n",
    "    \n",
    "    X_new = final_ranker.build_pair_features_for_one_resume(\n",
    "        resume_emb, job_embeddings, bm25, job_tokens_list, cleaned\n",
    "    )\n",
    "    scores = final_ranker.predict(X_new)\n",
    "\n",
    "    ranked = []\n",
    "    for j_idx, score in enumerate(scores):\n",
    "        job_tokens = set(job_tokens_list[j_idx])\n",
    "        ranked.append({\n",
    "            \"title\": jobs_df.iloc[j_idx][\"Business Title\"],\n",
    "            \"id\": j_idx,\n",
    "            \"skills\": job_tokens,\n",
    "            \"score\": float(score)\n",
    "        })\n",
    "\n",
    "    ranked_df = pd.DataFrame(ranked)\n",
    "    ranked_unique = (ranked_df.groupby(\"title\", as_index=False)\n",
    "                                .agg({\"score\": \"max\"}))\n",
    "    \n",
    "    ranked_unique = ranked_unique.sort_values(\"score\", ascending=False).head(5)\n",
    "    \n",
    "    for _, row in ranked_unique.iterrows():\n",
    "        print(f\"  {row['title']} (score: {row['score']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef6a63-057d-4fc0-914e-c54045fb87d8",
   "metadata": {},
   "source": [
    "## Analysis & Improvements\n",
    "### Current Strengths\n",
    "- Semantic + Lexical Fusion: By combining transformer embeddings, BM25 scores, and token overlap, the model captures both deep semantic similarity and surface-level keyword alignment. This hybrid approach is stronger than using embeddings or BM25 alone.\n",
    "- Weak Labeling Heuristics: The use of embedding similarity percentiles and Jaccard thresholds provides a practical way to generate training labels without manual annotation. While noisy, it enables scalable training.\n",
    "- Ranking Model (LambdaRank): LightGBM’s LambdaRank objective is well-suited for ranking tasks, optimizing directly for NDCG and ensuring that top results are prioritized.\n",
    "- Evaluation Metrics: Precision@5, NDCG@10, separation, diversity entropy, and duplicate penalties broaden and strengthen ranking quality, balancing relevance, diversity, and redundancy.\n",
    "\n",
    "### Observed Limitations\n",
    "\n",
    "Stop-word Handling: The current stop-word list is manually defined. This risks being:\n",
    "- Too broad (removing informative domain terms like “management” in some contexts).\n",
    "- Too narrow (missing high-frequency filler words not in the list).\n",
    "- Domain-misaligned (generic stop-words may not reflect the job/resume corpus).\n",
    "\n",
    "Feature Scope: Current features focus on text similarity and token overlap.\n",
    "- Important structured attributes (salary, employment type, seniority, department) are not yet incorporated. This limits the model’s ability to capture practical job–resume fit.\n",
    "\n",
    "Weak Label Noise: The heuristic labeling (embedding percentile + Jaccard) may misclassify borderline cases, introducing noise into training.\n",
    "Evaluation Ground Truth: Metrics are based on weak labels rather than human-annotated relevance judgments, so they measure internal consistency more than true accuracy.\n",
    "\n",
    "Limited training data and jobs: Both input files are approximately 3000 rows large. Many jobs will not be covered within these files, therefore, the model would not be able to predict any jobs that fall outside the scope of the training data. \n",
    "\n",
    "### Planned Improvements\n",
    "- Automatic Stop-word Detection. Replace static stop-word lists with corpus-driven methods (e.g., TF-IDF thresholds, entropy-based filtering, or embedding-cluster detection). This ensures the stop-word set adapts to the domain and avoids arbitrary exclusions.\n",
    "- Incorporate structured job attributes such as: Salary range (aligns with candidate expectations), Employment type (full-time, part-time, contract), Seniority level (junior, mid, senior), Department/Division (engineering, finance, HR). These features can be encoded as categorical embeddings or one-hot vectors and concatenated with text-based features.\n",
    "- Explore semi-supervised learning or active learning to refine labels with minimal human input.\n",
    "- Use pairwise preference signals (e.g., “Resume A is a better fit for Job X than Resume B”) to reduce noise.\n",
    "- Evaluation with Human Judgments\n",
    "- Collect a small set of human-annotated resume–job matches to benchmark the model. This would provide a more reliable measure of accuracy than weak labels alone.\n",
    "- Automate hyperparameter sweeps for thresholds (embedding similarity percentile, Jaccard cutoff).\n",
    "- Log diagnostics and leaderboard results for reproducibility and empirical tuning\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
